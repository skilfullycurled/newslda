{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup, NavigableString, Tag \n",
    "\n",
    "from nltk.util import ngrams\n",
    "from nltk import word_tokenize\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import collections\n",
    "import csv\n",
    "\n",
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "\n",
    "from pathlib2 import Path\n",
    "\n",
    "print \"imported\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS SPECIFIC TO TOPIC MODELING\n",
    "\n",
    "import langid\n",
    "import nltk\n",
    "import re\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from configparser import ConfigParser\n",
    "from gensim import corpora, models, similarities\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from string import digits\n",
    "import pyLDAvis.gensim\n",
    "print \"imported\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/alexperrier/datatalks/blob/master/twitter/twitter_lda.py\n",
    "# https://radimrehurek.com/gensim/wiki.html\n",
    "# https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/\n",
    "# https://miningthedetails.com/blog/python/lda/GensimLDA/\n",
    "# https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/lda_training_tips.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GENSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# INITIALIZE PARAMETERS\n",
    "\n",
    "num_topics = 10\n",
    "passes = 100\n",
    "iterations = 400\n",
    "eta = 'auto'\n",
    "alpha = 'auto' #0.001\n",
    "eval_every = None\n",
    "\n",
    "# LOAD FILENAMES\n",
    "# filepath = Path('data/dicts/')\n",
    "# files = [filename.stem for filename in filepath.iterdir() if filename.is_file()]\n",
    "# ['bnn_00_full','bnn_01_uni',...'wsj_06_lemmas','wsj_07_freq']\n",
    "\n",
    "# TEMP B/C PROGRAM DID NOT RUN ALL MODELS\n",
    "filepath = Path('data/dicts/')\n",
    "files = [filename.stem for filename in filepath.iterdir() if (filename.is_file() and ('bnn' not in filename.name))]\n",
    "\n",
    "# CREATE LDA MODELS\n",
    "for filename in files:\n",
    "    \n",
    "    #INPUT PATHS \n",
    "    dict_path = 'data/dicts/'\n",
    "    corpus_path = 'data/corpora/'\n",
    "\n",
    "    dict_filename   = dict_path + filename + '.dict'\n",
    "    corpus_filename = corpus_path + filename + '.mm'\n",
    "    \n",
    "    # NOT ENTIRELY CLEAR WHY I'VE CHOSEN TO USE A DICT HERE WHEN PARAMS ARE ABOVE...AH WELL...\n",
    "    lda_params      = {'num_topics': num_topics, 'passes': passes, 'iterations': iterations, \n",
    "                       'eta':eta, 'alpha': alpha, 'eval_every': eval_every}\n",
    "\n",
    "    # LOAD CORPUS AND DICTIONARY\n",
    "    corpus = corpora.MmCorpus(corpus_filename)\n",
    "    dictionary = corpora.Dictionary.load(dict_filename)\n",
    "    \n",
    "    # RUN LDA\n",
    "    print(\"Running LDA for: %s with params %s\" % (filename, lda_params.values()))\n",
    "    lda = models.LdaModel(corpus, id2word=dictionary,\n",
    "                          num_topics=lda_params['num_topics'], passes=lda_params['passes'],\n",
    "                          iterations=lda_params['iterations'], eta=lda_params['eta'], \n",
    "                          alpha=lda_params['alpha'], eval_every=lda_params['eval_every'])\n",
    "    \n",
    "    # OUTPUT PATH\n",
    "    lda_path = 'data/lda/gensim/'\n",
    "    lda_filename    = lda_path + filename + '.lda'\n",
    "    \n",
    "    # SAVE MODEL\n",
    "    lda.save(lda_filename)\n",
    "    \n",
    "    print(\"lda saved in %s \\n\" % lda_filename)\n",
    "    \n",
    "# Running LDA for: bnn_00_full with {'eval_every': None, 'passes': 100, 'num_topics': 10, 'eta': 'auto', 'iterations': 400, 'alpha': 'auto'}\n",
    "# lda saved in data/lda/gensim/bnn_00_full.lda "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MALLET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: Not using at this time due to questions about removal of stop words. It would appear as though the convert_input function has this flag set to true.  This function is the first thing that runs inside of the train function below.\n",
    "\n",
    "See: https://github.com/RaRe-Technologies/gensim/blob/8b810918d59781116794a6679999afdc76b857ef/gensim/models/wrappers/ldamallet.py#L246"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# PART 16 https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/\n",
    "\n",
    "mallet_path = 'data/mallet-2.0.8/bin/mallet'\n",
    "\n",
    "files = [filename.split('.')[0] for filename in os.listdir('data/dicts/') if not filename.startswith('.')]\n",
    "files = files[1:] # REMOVE 'ALL' FOLDER\n",
    "# ['cnn_level_zero', 'cnn_level_one',... 'month_d_level_five','month_d_level_six']# print files\n",
    "\n",
    "for filename in files:\n",
    "    \n",
    "    dict_path = 'data/dicts/'\n",
    "    corpus_path = 'data/corpora/'\n",
    "    lda_path = 'data/lda/mallet/'\n",
    "\n",
    "    dict_filename   = dict_path + filename + '.dict'\n",
    "    corpus_filename = corpus_path + filename + '.mm'\n",
    "    lda_filename    = lda_path + filename + '.lda'\n",
    "    \n",
    "    corpus = corpora.MmCorpus(corpus_filename)\n",
    "    dictionary = corpora.Dictionary.load(dict_filename)\n",
    "    \n",
    "    lda = models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=10, id2word=dictionary)\n",
    "    lda.save(lda_filename)\n",
    "    \n",
    "# bnn_level_one = lda.load('data/lda/bnn_level_one.lda')\n",
    "# bnn_level_one.show_topics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
